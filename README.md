# Инструмент для подготовки данных для моделей GLiNER

### !!! Проект еще в работе !!!

Этот проект позволяет автоматически размечать данные для обучения GLiNER при помощи больших языковых моделей (LLM). 

## Что такое GLiNER?

GLiNER (Generalist and Lightweight Model for Named Entity Recognition) — это модель для распознавания именованных сущностей (NER), способная идентифицировать любые типы сущностей с помощью BERT. Она предоставляет практичную альтернативу традиционным NER-моделям, которые ограничены предопределенными типами сущностей, и крупным языковым моделям (LLM), которые, несмотря на свою гибкость, являются дорогостоящими и громоздкими для использования в условиях ограниченных ресурсов.

### Источник данных

В качестве источника данных на данный момент можно использовать файлы экспорта телеграмм каналов. В новостных каналах текст содержит достаточно много сущностей, поэтому он хорошо подходит для обучения NER моделей. 

### Логика обработки

Обрабатываемые данные хранятся в табличке texts.csv
Она создается при запуске программы, и в нее заносятся все тексты, которые доступны в файле экспорта телеграмма. 
Далее таблица будет наполняться по мере исполнения программы. 
Для каждого текста будет написано его краткое содержание (таким образом мы можем немного увеличить наш набор данных). 
Затем для каждого текста и его краткого содержания будет выполнен процесс извлечения именованных сущностей, при помощи LLM. 
* Некоторые провайдеры LLM поддерживают structured output, что сильно помогает. Для других же приходится указывать нужную структуру ответа в промпте. 

Сейчас добавляю дополнительный промпт, который попросит LLM оценить данный ей текст на пригодность в качестве обучающих данных. Для этого у нее есть критерии оценки. 

Для моделей gemeni реализован подсчет использованных токенов. 

### Результат

После заполнения таблицы будет создан json файл. Этот файл будет в том же формате, что нужен для дообучения GLiNER модели.
Блокнот для дообучения GLiNER можно найти на их гитабе в примерах.  

### Установка

Установить зависимости через 
```bash
pip install -r requirements.txt
```

В корне должен лежать файл `.env`, в котором будут заданы ваши ключи, в формате:
```
MISTRAL_API_KEY=key123
MISTRAL_MODEL=mistral-model-name

GOOGLE_API_KEY = ...
GOOGLE_MODEL="gemini-1.5-flash"
```